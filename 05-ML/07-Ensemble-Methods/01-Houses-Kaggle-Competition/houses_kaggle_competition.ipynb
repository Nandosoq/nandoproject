{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:28:54.927307Z",
     "start_time": "2021-02-03T08:28:52.939178Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:40.887551Z",
     "start_time": "2021-02-03T08:29:40.717826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell to regroup all your imports\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• LeWagon Kaggle Batch Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/lewagon/data-images/blob/master/ML/kaggle-batch-challenge.png?raw=true' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your first Kaggle competition!\n",
    "\n",
    "Your objective is to **submit online an answer** to the open competition [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "- Fortunately, you have already come across the house dataset in the bootcamp!\n",
    "- You will be semi-guided up to a **baseline model**\n",
    "- Only after will you be free to improve & refine your models\n",
    "- We will approach the problem through **pipelines** (the best practice to take!)\n",
    "\n",
    "A word on Kaggle:\n",
    "- Kaggle will rank your submission amongst all participants!\n",
    "- But don't worry, everyone is publicly removed from the leaderboard after 2 months\n",
    "- You can make to 10 submissions per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Kaggle\n",
    "\n",
    "üëâ Create an account on Kaggle if you want to participate in the competition. \n",
    "\n",
    "üëâ Join the [House Prices Challenge](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) \n",
    "\n",
    "üëâ Write down your Kaggle `username` the [result spreadsheet here](https://docs.google.com/spreadsheets/d/1ZEBKwa_k1Ytb0WCOh-Nopq3eaezwBNu1SAqKXEXRguc/edit#gid=0) (pick the correct batch!)\n",
    "\n",
    "**Your whole class will compete as a group against the team of TAs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already downloaded for you everything from Kaggle into your current notebook folder:\n",
    "- `train.csv` is your (1460 * 81) training set containing `X` and `y`\n",
    "- `test.csv` is your (1459 * 80) testing set without the associated target `y`!\n",
    "- `sample_submission.csv` describing the format required to submit your answer\n",
    "- `data_description.txt` describing all columns\n",
    "\n",
    "Your goal is to predict the `y_pred` missing from your test set and submit it to discover your test_score & ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Load the train dataset in a DataFrame `data` and create your `X` and `y`. Inspect their shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:28:55.731767Z",
     "start_time": "2021-02-03T08:28:55.316322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use this direct download link if you don't want to create a Kaggle account\n",
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dup = data.drop_duplicates()\n",
    "\n",
    "duplicate_count = len(data) - len(data_dup)\n",
    "duplicate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üê£ BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial feature overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80 features is too much to deal with one-by-one for a first baseline pipeline! Let's treat them solely based on their `dtype`:\n",
    "\n",
    "‚ùì How many numerical features vs. categorical features do we have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:28:59.700769Z",
     "start_time": "2021-02-03T08:28:59.692442Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_categorical =[]\n",
    "feat_numerical = []\n",
    "\n",
    "for i in X.columns:\n",
    "    \n",
    "    if X[i].dtypes == 'int64' or X[i].dtypes == 'float64':\n",
    "        \n",
    "        feat_numerical.append(i)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        feat_categorical.append(i)\n",
    "    \n",
    "    #print (f' {i}:{X[i].dtypes}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_numerical\n",
    "\n",
    "feat_numerical.remove(\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Store the Series `feat_categorical_nunique` containing the number of **unique values** for each categorical feature in our training set. How many unique categories are there in total ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_966/3061097868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeat_categorical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcat_dict_nunique\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "cat_dict_nunique = {\n",
    "\n",
    "}\n",
    "\n",
    "for i in feat_categorical:\n",
    "#\n",
    "    cat_dict_nunique[i] = len(X[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_dict_nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:00.579358Z",
     "start_time": "2021-02-03T08:29:00.566973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSZoning': 5,\n",
       " 'Street': 2,\n",
       " 'Alley': 3,\n",
       " 'LotShape': 4,\n",
       " 'LandContour': 4,\n",
       " 'Utilities': 2,\n",
       " 'LotConfig': 5,\n",
       " 'LandSlope': 3,\n",
       " 'Neighborhood': 25,\n",
       " 'Condition1': 9,\n",
       " 'Condition2': 8,\n",
       " 'BldgType': 5,\n",
       " 'HouseStyle': 8,\n",
       " 'RoofStyle': 6,\n",
       " 'RoofMatl': 8,\n",
       " 'Exterior1st': 15,\n",
       " 'Exterior2nd': 16,\n",
       " 'MasVnrType': 5,\n",
       " 'ExterQual': 4,\n",
       " 'ExterCond': 5,\n",
       " 'Foundation': 6,\n",
       " 'BsmtQual': 5,\n",
       " 'BsmtCond': 5,\n",
       " 'BsmtExposure': 5,\n",
       " 'BsmtFinType1': 7,\n",
       " 'BsmtFinType2': 7,\n",
       " 'Heating': 6,\n",
       " 'HeatingQC': 5,\n",
       " 'CentralAir': 2,\n",
       " 'Electrical': 6,\n",
       " 'KitchenQual': 4,\n",
       " 'Functional': 7,\n",
       " 'FireplaceQu': 6,\n",
       " 'GarageType': 7,\n",
       " 'GarageFinish': 4,\n",
       " 'GarageQual': 6,\n",
       " 'GarageCond': 6,\n",
       " 'PavedDrive': 3,\n",
       " 'PoolQC': 4,\n",
       " 'Fence': 5,\n",
       " 'MiscFeature': 5,\n",
       " 'SaleType': 9,\n",
       " 'SaleCondition': 6}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict_nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:01.356212Z",
     "start_time": "2021-02-03T08:29:01.352760Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î If we were to `OneHotEncode` all categorical features, our feature matrix `X_preproc` would become pretty big and spare, with almost 300 (highly correlated) features for only 1400 observations. Ideally, we should aim at feeding our model with 50-100 features max (üìö Read this [rule of thumb](https://datascience.stackexchange.com/a/11480/98300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 main strategies to reduce the number of categorical features post-preprocessing:\n",
    "- **[Remove](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)** features that bring too little explanation to our model. This may require statistical analysis of feature importance \n",
    "- **[Ordinally encode](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)** (instead of one-hot-encode) categorical features into integers. However this forces a notion of \"order\" (1>2>3...) that can be detrimental if not set properly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the **histogram** of number of unique value per categorical feature. Do you see some quick wins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:02.706410Z",
     "start_time": "2021-02-03T08:29:02.540040Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° As a starter, what about simply removing all features that have **7 unique values or more**, and one-hot-encode every others? Let's keep ordinal encoding and statistical feature selection for the next iteration.\n",
    "\n",
    "‚ùì Store features to OHE in a list `feat_categorical_small` below. How many features will be OHE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "notunique = pd.DataFrame(X[feat_categorical].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features to one-hot-encode\n",
    "notunique = pd.DataFrame(X[feat_categorical].nunique())\n",
    "feat_categorical_small = notunique[notunique[0]<7].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code below (and clear the cell once it passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:10.601850Z",
     "start_time": "2021-02-03T08:29:08.693622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.6, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 -- /home/nandosoq/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/nandosoq/code/Nandosoq/data-challenges/05-ML/07-Ensemble-Methods/01-Houses-Kaggle-Competition\n",
      "plugins: anyio-3.2.1, dash-1.21.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_features_overview.py::TestFeaturesOverview::test_feat_categorical_small \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/features_overview.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed features_overview step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('features_overview',\n",
    "    n=len(feat_categorical_small))\n",
    "result.write(); print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline - V1 minimal baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "‚ùì Let's code the basic preprocessing pipeline described below. Save it under `preproc_baseline`.\n",
    "\n",
    "For categorical features\n",
    "- Simple-Impute with most frequent values\n",
    "- One-Hot-Encode features that have less than 7 unique values to start with\n",
    "- Drop all others features\n",
    "\n",
    "\n",
    "As for numerical features\n",
    "- Simple-Impute with strategy 'mean'\n",
    "- Min-Max Scale \n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>‚ÑπÔ∏è Pro tips</summary>\n",
    "\n",
    "If you are confident, you can try sklearn's shorter syntax `make_pipeline` or `make_column_transformer` instead of the longer syntax `Pipeline` or `ColumnTransformer` if you want to avoid giving names manually to every steps.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 184)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing pipe\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaling', MinMaxScaler())\n",
    "])\n",
    "    \n",
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHotEncoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "preproc_baseline = ColumnTransformer([\n",
    "    ('num_encoder', num_transformer, feat_numerical)\n",
    "    ,('cat_encoder', cat_transformer, feat_categorical_small)\n",
    "],remainder='drop')\n",
    "\n",
    "preproc_baseline.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:46.327429Z",
     "start_time": "2021-02-03T08:29:46.298030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy code your pipeline first\n",
    "\n",
    "# Code it for real below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Look at the **shape** of your preprocessed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:48.945399Z",
     "start_time": "2021-02-03T08:29:48.899742Z"
    }
   },
   "outputs": [],
   "source": [
    "shape_preproc_baseline = preproc_baseline.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:51.189687Z",
     "start_time": "2021-02-03T08:29:50.059279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.6, pytest-6.2.4, py-1.10.0, pluggy-0.13.1 -- /home/nandosoq/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/nandosoq/code/Nandosoq/data-challenges/05-ML/07-Ensemble-Methods/01-Houses-Kaggle-Competition\n",
      "plugins: anyio-3.2.1, dash-1.21.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_preproc_baseline.py::TestPreprocBaseline::test_shape \u001b[31mFAILED\u001b[0m\u001b[31m   [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________ TestPreprocBaseline.test_shape ________________________\u001b[0m\n",
      "\n",
      "self = <test_preproc_baseline.TestPreprocBaseline testMethod=test_shape>\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_shape\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\n",
      ">       \u001b[96mself\u001b[39;49;00m.assertEqual(\u001b[96mself\u001b[39;49;00m.result.shape, (\u001b[94m1460\u001b[39;49;00m,\u001b[94m183\u001b[39;49;00m))\n",
      "\u001b[1m\u001b[31mE       AssertionError: Tuples differ: (1460, 184) != (1460, 183)\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE       First differing element 1:\u001b[0m\n",
      "\u001b[1m\u001b[31mE       184\u001b[0m\n",
      "\u001b[1m\u001b[31mE       183\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE       - (1460, 184)\u001b[0m\n",
      "\u001b[1m\u001b[31mE       ?          ^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE       + (1460, 183)\u001b[0m\n",
      "\u001b[1m\u001b[31mE       ?          ^\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_preproc_baseline.py\u001b[0m:6: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED tests/test_preproc_baseline.py::TestPreprocBaseline::test_shape - Asse...\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('preproc_baseline',\n",
    "    shape=shape_preproc_baseline)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Pipe a basic Ridge regressor to your `preproc_baseline` and store it to `pipe_baseline` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:52.307918Z",
     "start_time": "2021-02-03T08:29:52.248129Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_baseline = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Read the Kaggle [contest evaluation rules](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) \n",
    "- Which performance metric do you need? Is it readily available in sklearn?\n",
    "- Create a scorer using [`make_scorer`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) and store it into a variable named `rmsle`\n",
    "- Create also the negative score `rmsle_neg` which is best when _maximized_. This will come handy later as `GridSearchCV` requires a score to _maximize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:48:25.203103Z",
     "start_time": "2021-02-03T08:48:25.197636Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì5-fold cross_validate your `pipe_baseline` using this metric to get a first glance at your baseline perf.    \n",
    "Store your mean score as `score_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:56.980617Z",
     "start_time": "2021-02-03T08:29:56.716448Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_baseline = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Predict `y_pred_baseline` from the Kaggle `test.csv` dataset you stored in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:29:58.984163Z",
     "start_time": "2021-02-03T08:29:58.586080Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Finally, store your CSV ready to be submitted as `submission_baseline.csv` in the `data` folder. Read carefully the Kaggle required format and test it below (you don't need to submit this baseline online for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:30:00.911236Z",
     "start_time": "2021-02-03T08:30:00.904484Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T08:30:06.294037Z",
     "start_time": "2021-02-03T08:30:05.002420Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "tmp = pd.read_csv(\"data/submission_baseline.csv\")\n",
    "result = ChallengeResult('submission_baseline',\n",
    "    score_baseline = score_baseline,\n",
    "    submission_shape = tmp.shape,\n",
    "    submission_columns = list(tmp.columns),\n",
    "    submission_dtypes = str(list(tmp.dtypes)),\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèãÔ∏è‚Äç‚ôÄÔ∏è ITERATIONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ üéâ Congratulation for having fully pipelined a basline model! You will see now how easier it is to iterate and improve performance üöÄ\n",
    "\n",
    "- Your goal is to improve your prediction and submit it by **16h30 max online**\n",
    "- We suggested you some improvements below\n",
    "- **Pick up your fights** and **incrementally** improve your pipeline as you see fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "- Linear Models: fine-tune regularization ?\n",
    "- **Tree-based ensembles (must try today)**: Probably the best suited for many categorical-features problems\n",
    "- Stacking !\n",
    "- ...\n",
    "\n",
    "**Preprocessing** (once your first ensemble models works)\n",
    "\n",
    "- Ordinal Encoding of categorical features with a hidden notion of order in their values (e.g. \"bad\", \"average\", good\")\n",
    "- Statistical Feature Selection to remove useless features (avoid overfitting and reduce train time)\n",
    "- Predict log(SalePrice) instead?\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Iteration (‚ö†Ô∏è come back here after your first Ensemble model)\n",
    "\n",
    "‚è© Collapse me if you don't use me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding (1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Look at the following feature below. Couldn't it be encoded numerically in a wise manner?\n",
    "```\n",
    "ExterQual: Evaluates the quality of the material on the exterior \n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Luckily, the `OrdinalEncoder` and its argument `categories`  allows us to do just that. Check it out below and make sure to understand how ths works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T15:51:51.765333Z",
     "start_time": "2021-02-02T15:51:51.758709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define specific order for features\n",
    "# Note: if you change this order, it will change the output for .transform()\n",
    "feature_A_sorted_values = ['bad', 'average', 'good'] \n",
    "feature_B_sorted_values = ['dirty', 'clean', 'new']\n",
    "\n",
    "encoder = OrdinalEncoder(\n",
    "    categories=[\n",
    "        feature_A_sorted_values,\n",
    "        feature_B_sorted_values\n",
    "    ],\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "\n",
    "# Just some random training data\n",
    "XX = [\n",
    "    ['good', 'dirty'],\n",
    "    ['bad', 'new'],\n",
    "    ['average', 'clean'],\n",
    "]\n",
    "\n",
    "encoder.fit(XX)\n",
    "\n",
    "encoder.transform([\n",
    "        ['bad', \"dirty\"],\n",
    "        ['good', 'new'],\n",
    "        ['bad', 'oooops never seen this label before']\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "‚ùì **Your turn**: split your categorical preprocessor into\n",
    "\n",
    "- `preproc_ordinal` to ordinally encode **some features** of your choice (**do a quick iteration first**)\n",
    "- `preproc_nominal` to one hot encode the other ones\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "- You won't be able to avoid hard-coding names and ordered values of features! Be tidy!\n",
    "- It's a good practice to sort alphabetically your features to avoid bad surprises\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T16:11:15.997343Z",
     "start_time": "2021-02-02T16:11:15.977031Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Target engineering (15 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "‚ùì We are asked to minimize the RMS**L**E. Why don't we transform our target to directly predict its log?\n",
    "- Check-out historgram of your target `y`. Normally distributed variables should be easier to predict with linear models. \n",
    "- Create `y_log` and your new performance metrics\n",
    "- Don't forget at the end to take the exponential of your predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T15:51:52.314746Z",
     "start_time": "2021-02-02T15:51:51.942808Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Feature Selection (1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to remove the least interesting features, to limit overfitting and shorten training time.  \n",
    "Choose one of the 3 options below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### (option 1 - recommended) univariate feature selection based on relationship with target `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "‚ùì We will use sklearn's [feature selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) tools directly in your pipeline.\n",
    "- Add a `SelectPercentile` filter (coupled with `mutual_info_regression` for the statistical test to use) at the end of your `preproc` pipeline.\n",
    "- This will filter-out features that, - taken individually - least explain your target!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### (option 2) multivariate feature selection based their common relationship with target `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "‚ùì We will use sklearn's [feature selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) tools directly in your pipeline.\n",
    "- Add a `SequentialFeatureSelector` at the end of your `preproc` pipeline.\n",
    "- This will recursively filter-out least important features according to `feature_permutation` importance!  \n",
    "- Probably overkill for such small dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (option 3) Filter based only on the properties of `X` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Use Pearson's correlation combined with a heatmap...\n",
    "- to check visually whether some **numerical** features almost entirely explain others. \n",
    "- Then, create a \"filter\" in your pipeline that removes any correlated below a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T15:51:54.086492Z",
     "start_time": "2021-02-02T15:51:54.084287Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Use [Spearman's rank correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) combined with a heatmap...\n",
    "- to whether some **ordinally encoded** features are almost entirely \"ordered\" similarily than others\n",
    "- Then, create a \"filter\" in your pipeline that removes any ordinal features correlated below a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T15:51:54.378627Z",
     "start_time": "2021-02-02T15:51:54.376048Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Another way to filter out feature relies solely on removing those with the lowest variance.  \n",
    "- Think about it: a feature which only takes one value is useless (and has a variance of 0).  \n",
    "- Try to add a `VarianceThreshold` to the end of your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T15:51:55.855088Z",
     "start_time": "2021-02-02T15:51:55.853045Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Final preproc pipeline\n",
    "‚ùì store here your final version of the preproc pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T19:56:27.306869Z",
     "start_time": "2021-02-02T19:56:27.161247Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÖFINAL SUBMISSION (start at 4h30 max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discover your real test score by submitting on Kaggle! \n",
    "\n",
    "üëâ Write down your test score on the [result spreadsheet here](https://docs.google.com/spreadsheets/d/1ZEBKwa_k1Ytb0WCOh-Nopq3eaezwBNu1SAqKXEXRguc/edit#gid=0) (pick the correct batch!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T14:05:37.861551Z",
     "start_time": "2021-01-27T14:04:03.536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
