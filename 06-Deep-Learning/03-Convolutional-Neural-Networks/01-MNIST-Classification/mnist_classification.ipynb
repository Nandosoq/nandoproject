{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning week - Day 3 - Mnist classification\n",
    "\n",
    "### Exercise objectives\n",
    "- Implement a CNN architecture with convolution layers\n",
    "- Run a Neural Network on images\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "Let's imagine for a moment that you are working for the postal office (and you're in 1970 / 1980). You deal everyday with a enourmous amont of letters, and you want to automate the process of reading the numbers that have been handwritten. This task, called the _Handwriting Recognition_, has been a very complex that has been handled by Bell Labs (among other) where Yann Le Cun used to work, and where such things have been developed : \n",
    "\n",
    "![Number recognition](recognition.gif)\n",
    "\n",
    "\n",
    "The idea is that you have an image (not a video: the animation is here to present what happens with different images) as an input and you try to predict the figure on the image - it corresponds to a classification task, where the output is the class (=figure) the image belongs to, from 0 to 9.\n",
    "\n",
    "This task used to be quite complex back in the time, and still is a benchmark on which a lot of people work. For this reason, the MNIST (for *Modified ou Mixed National Institute of Standards and Technology*) dataset has been created: it corresponds to digit images, from 0 to 9. \n",
    "\n",
    "You goal in this notebook is to build a Convolution Neural Network that can work on such images and predict the corresponding class of each digit image. Keep in mind that this CNN will make you classify hand-written digits, which was a very complex task till the 90's. \n",
    "\n",
    "## The data\n",
    "\n",
    "Keras provides multiple datasets within the Python package. You can load it with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:19.145710Z",
     "start_time": "2021-04-29T07:22:14.174055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:22:19.171006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-25 14:22:19.171051: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ Let's look at some of the data. \n",
    "\n",
    "Select some of the values of the train set and plot them thanks to the `imshow` function from matplotlib with `cmap` set to `gray`(otherwise, the displayed colors are just some arrangement Matplotlib does, which does not exist in practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:19.731522Z",
     "start_time": "2021-04-29T07:22:19.148711Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(X_train.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train[0], cmap=\"gray\");\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_train[1], cmap=\"gray\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that neural networks converge faster when the input data are somehow normalized? It goes similarly for input images. \n",
    "\n",
    "❓ Question ❓ As a first preprocessing step, you should normalize your data. For images, it simply implies to divide your input data by the maximal value, i.e. 255. Don't forget to do it on your train and test data.\n",
    "\n",
    "(N.B.: you can also centered your data, by substracting 0.5 but it is not mandatory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.043153Z",
     "start_time": "2021-04-29T07:22:19.734478Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ What is the shape of your images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.050056Z",
     "start_time": "2021-04-29T07:22:20.046331Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that you have 60.000 training images, all of size (28, 28). However, Keras needs images whose last dimension is the number of channels, which is missing here.\n",
    "\n",
    "❓ Question ❓ Use the `expand_dims` to add one dimension at the end of the training and test data. Then, print the shape of X_train and X_test that should respectively be (60000, 28, 28, 1) and (10000, 28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.063475Z",
     "start_time": "2021-04-29T07:22:20.052948Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:22:27.502530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-25 14:22:27.502570: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-25 14:22:27.502588: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Nandosoq): /proc/driver/nvidia/version does not exist\n",
      "2021-08-25 14:22:27.502797: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.backend import expand_dims\n",
    "\n",
    "X_train = expand_dims(X_train, -1)\n",
    "\n",
    "X_test  = expand_dims(X_test , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60000, 28, 28, 1] [10000, 28, 28, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape.as_list(),X_test .shape.as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A last thing to do to prepare your data is to convert your labels to one-hot encoded categories.\n",
    "\n",
    "❓ Question ❓ Use `to_categorical` to transform your labels. Store the results in `y_train_cat` and `y_test_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:20.845683Z",
     "start_time": "2021-04-29T07:22:20.840921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One Hot Encode our Target for TensorFlow processing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_cat_train = to_categorical(y_train, num_classes=10)\n",
    "y_cat_test = to_categorical(y_test, num_classes=10)\n",
    "y_cat_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are now ready to be used.\n",
    "\n",
    "## The Convolutional Neural Network _aka_ CNN\n",
    "\n",
    "Now, build a Convolutional Neural Network. \n",
    "\n",
    "❓ Question ❓ Based on the course, build a neural network that has:\n",
    "- a `Conv2D` layer with 8 filters, each of size (4, 4), with an input shape suitable for your task, the relu activation function, and padding='same' so as to \n",
    "- a `MaxPool2D` layer with a pool_size of (2, 2)\n",
    "- a second `Conv2D` layer with 16 filters, each of size (3, 3), and the relu activation function\n",
    "- a second `MaxPool2D` layer with a pool_size of (2, 2)\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the relu activation function\n",
    "- a last layer that is suited for your task\n",
    "\n",
    "In the function, do not forget to include the compilation of the model, which optimizes the `categorical_crossentropy` with the adam optimizer - and the accuracy should be among the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#a Conv2D layer with 8 filters, each of size (4, 4), with an input shape suitable for your task, \n",
    "#the relu activation function, and padding='same' so as to\n",
    "model.add(layers.Conv2D(8, (4,4), input_shape=(28, 28, 1), padding='same', activation=\"relu\"))\n",
    "\n",
    "#a MaxPool2D layer with a pool_size of (2, 2)\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#a second Conv2D layer with 16 filters, each of size (3, 3), and the relu activation function\n",
    "model.add(layers.Conv2D(16, (3,3), padding='same', activation=\"relu\"))\n",
    "\n",
    "#a second MaxPool2D layer with a pool_size of (2, 2)\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#a Flatten layer\n",
    "model.add(layers.Flatten())\n",
    "#a first Dense layer with 10 neurons and the relu activation function\n",
    "model.add(layers.Dense(10, activation='relu')) # intermediate layer\n",
    "\n",
    "#a last layer that is suited for your task\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:24.419923Z",
     "start_time": "2021-04-29T07:22:24.415553Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    ### First convolution & max-pooling\n",
    "    model.add(layers.Conv2D(8, (4,4), input_shape=(28, 28, 1), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    ### Second convolution & max-pooling\n",
    "    model.add(layers.Conv2D(16, (3,3), padding='same', activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    ### Flattening\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    ### One fully connected\n",
    "    model.add(layers.Dense(10, activation='relu')) # intermediate layer\n",
    "\n",
    "    ### Last layer (let's say a classification with 10 output)\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    ### Model compilation\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ How many trainable parameters are there in your model?\n",
    "- Compute them with `model.summary()` first\n",
    "- Recompute them manually layer per layer then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:47.154385Z",
     "start_time": "2021-04-29T07:22:47.146231Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 8)         136       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 9,264\n",
      "Trainable params: 9,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Question ❓ Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a validation set and an early stopping criterion. \n",
    "- Limit at 5 epoch max in this challenge (just to save time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T07:22:50.611532Z",
     "start_time": "2021-04-29T07:22:50.608695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb9ac6e160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Classification with more classes\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_cat_train,\n",
    "          batch_size=16, \n",
    "          epochs=1,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es],\n",
    "          verbose=0)\n",
    "            #,          njobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably see that the model converges within few epochs. The reason is that there are as many weight update as there are batches within each epoch. For instance, if you batch_size is of 32, you have 60.000/32 = 1875 updates.\n",
    "\n",
    "\n",
    "❓ Question ❓ What is your accuracy on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-27T15:11:42.884017Z",
     "start_time": "2021-04-27T15:11:42.372506Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732000231742859"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "model.evaluate(X_test, y_cat_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should be already impressed by your skills! You solved what was a very hard problem 30 years ago with your CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Congratulation! Don't forget to commit and push your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
